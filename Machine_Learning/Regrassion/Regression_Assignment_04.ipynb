{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebab8260",
   "metadata": {},
   "source": [
    "# Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4fcc5",
   "metadata": {},
   "source": [
    "This is a **regularization technique** used in feature selection using a **Shrinkage method** also referred to as the **penalized regression method.** \n",
    "\n",
    "Lasso is short for Least Absolute Shrinkage and Selection Operator, which is used both for **regularization and model selection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a777de8",
   "metadata": {},
   "source": [
    "# Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4113b73",
   "metadata": {},
   "source": [
    "The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the **model does some automatic feature selection to decide which features should and should not be included on its own.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6db00",
   "metadata": {},
   "source": [
    "# Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455296b5",
   "metadata": {},
   "source": [
    "Interpreting the coefficients in a Lasso Regression model involves considering both the magnitude and the sign of each coefficient:\n",
    "\n",
    "* **Magnitude of Coefficients:** The magnitude of a coefficient indicates the strength of the relationship between the corresponding independent variable and the dependent variable. Larger coefficient magnitudes suggest a stronger impact on the target variable. However, in Lasso, coefficients can be shrunk all the way to zero, which implies that the associated feature is considered irrelevant by the model.\n",
    "\n",
    "* **Sign of Coefficients:** The sign of a coefficient (positive or negative) indicates the direction of the relationship between the independent variable and the dependent variable. A positive coefficient suggests that as the independent variable increases, the dependent variable tends to increase as well. A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc023ce",
   "metadata": {},
   "source": [
    "# Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1c026",
   "metadata": {},
   "source": [
    "**A tuning parameter (Î»)**, sometimes called a **penalty parameter,** controls the strength of the penalty term in ridge regression and lasso regression. \n",
    "\n",
    "It is basically the **amount of shrinkage, where data values are shrunk towards a central point, like the mean.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672caab",
   "metadata": {},
   "source": [
    "# Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3391f3",
   "metadata": {},
   "source": [
    "It's not fast, but it will build nonlinear models and perform selection. \n",
    "To directly answer your question, **LASSO is a linear method, but you could make nonlinear terms through transformation and see if they stay in the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f8fbd",
   "metadata": {},
   "source": [
    "# Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d13fe1",
   "metadata": {},
   "source": [
    "The difference between ridge and lasso regression is that \n",
    "* **it tends to make coefficients to absolute zero as compared to Ridge which never sets the value of coefficient to absolute zero.**\n",
    "\n",
    "* **Ridge regression shrinks the coefficients towards zero, while Lasso regression encourages some of them to be exactly zero.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b17145",
   "metadata": {},
   "source": [
    "# Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f44b61",
   "metadata": {},
   "source": [
    "Another Tolerant Method for dealing with multicollinearity known as **Least Absolute Shrinkage and Selection Operator** (LASSO) regression, solves the same constrained optimization problem as ridge regression, but **uses the L1 norm rather than the L2 norm as a measure of complexity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e7a39",
   "metadata": {},
   "source": [
    "# Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7bd98",
   "metadata": {},
   "source": [
    "The best **cross-validation score** is obtained for the 0.4 value of lambda. This is your optimal value of lambda. This is how we choose the estimated best model with optimal hyper-parameter values. Use this same process with different types of algorithms like Ridge, LASSO, Elastic-Net, Random Forests, and Boosted trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df0ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf35e59",
   "metadata": {},
   "source": [
    "# Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f52828",
   "metadata": {},
   "source": [
    "**Simple linear regression** is a regression model that estimates the relationship between one independent variable and one dependent variable using a straight line.\n",
    "\n",
    "\n",
    "**Multiple Linear Regression** is one of the important regression algorithms which models the linear relationship between a single dependent continuous variable and more than one independent variable.\n",
    "\n",
    "**Difference:**\n",
    "* The main difference between simple and multiple regression is that multiple regression includes two or more independent variables – sometimes called predictor variables – in the model, rather than just one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24773689",
   "metadata": {},
   "source": [
    "# Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73348dc2",
   "metadata": {},
   "source": [
    "**Assumptions of Linear Regression:**\n",
    "\n",
    "* **Linearity:** The relationship between variables is linear.\n",
    "* **Independence:** Residuals are independent of each other.\n",
    "* **Homoscedasticity:** Residuals have constant variance.\n",
    "* **Normality:** Residuals are normally distributed.\n",
    "* **No Multicollinearity:** Independent variables are not highly correlated.\n",
    "* **No Autocorrelation:** Residuals show no pattern over time.\n",
    "\n",
    "**Checking Assumptions:**\n",
    "\n",
    "* **Visual Inspection:** Scatter plots, residual plots.\n",
    "* **Residual Analysis:** Patterns in residuals.\n",
    "* **Normality Tests:** Shapiro-Wilk, Anderson-Darling.\n",
    "* **Correlation Matrices:** Check multicollinearity.\n",
    "* **Autocorrelation Tests:** Autocorrelation plots, Durbin-Watson.\n",
    "* **Transformations:** Use when assumptions are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cac02e",
   "metadata": {},
   "source": [
    "# Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3166b5",
   "metadata": {},
   "source": [
    "The easiest way to understand and interpret slope and intercept in linear models is to first understand the slope-intercept formula: **y = mx + b.** **M is the slope or the consistent change between x and y, and b is the y-intercept.** \n",
    "\n",
    "Often, the **y-intercept represents the starting point of the equation.**\n",
    "\n",
    "**Interpret the slope:** If the speed of the club hitting the ball increases by 1 mph, then the model predicts that the length the ball travels increases by 57.66 yards. Interpret the intercept: If the ball is hit with a speed of 0 mph, then the model predicts that the length the ball travels will be 3.18 yards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68abfbc",
   "metadata": {},
   "source": [
    "# Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ab98f",
   "metadata": {},
   "source": [
    "* Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. \n",
    "\n",
    "* Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5630f6",
   "metadata": {},
   "source": [
    "# Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42087ac5",
   "metadata": {},
   "source": [
    "* Multiple regression is a broader class of regressions that encompasses linear and nonlinear regressions with multiple explanatory variables. \n",
    "\n",
    "* Whereas linear regress only has one independent variable impacting the slope of the relationship, multiple regression incorporates multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b9055",
   "metadata": {},
   "source": [
    "# Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5600656",
   "metadata": {},
   "source": [
    "**Multicollinearity** happens when independent variables in the regression model are highly correlated to each other.\n",
    "\n",
    "* It makes it hard to interpret of model and also creates an overfitting problem. \n",
    "* It is a common assumption that people test before selecting the variables into the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a0dec",
   "metadata": {},
   "source": [
    "# Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8534fb1",
   "metadata": {},
   "source": [
    "**A polynomial regression** model is a machine learning model that can capture non-linear relationships between variables by fitting a non-linear regression line, which may not be possible with simple linear regression. \n",
    "\n",
    "* It is used when linear regression models may not adequately capture the complexity of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566d106",
   "metadata": {},
   "source": [
    "# Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5909e",
   "metadata": {},
   "source": [
    "**Advantages of Polynomial Regression:**\n",
    "\n",
    "* **Flexibility in Modeling:** Polynomial regression can capture non-linear relationships between variables, allowing for a wider range of patterns and curves in the data to be fitted.\n",
    "\n",
    "* **Improved Fit:** In cases where the true relationship between variables is curvilinear, polynomial regression can provide a better fit compared to linear regression.\n",
    "\n",
    "* **Higher Order Effects:** Polynomial regression can capture higher-order effects, such as quadratic or cubic relationships, which might be relevant in certain scenarios.\n",
    "\n",
    "* **Better Approximation:** Polynomial regression can approximate complex functions with a limited number of terms, making it useful for situations where the true underlying relationship is not fully known.\n",
    "\n",
    "**Disadvantages of Polynomial Regression:**\n",
    "\n",
    "* **Overfitting:** With higher-degree polynomials, there's a risk of overfitting the model to noise in the data, leading to poor generalization to new, unseen data.\n",
    "\n",
    "* **Model Complexity:** As the degree of the polynomial increases, the model becomes more complex and harder to interpret. This can lead to difficulties in understanding the underlying relationships.\n",
    "\n",
    "* **Extrapolation Uncertainty:** Polynomial models might not extrapolate well beyond the range of observed data, leading to unreliable predictions outside the data range.\n",
    "\n",
    "* **Data Requirements:** Polynomial regression might require more data points compared to linear regression, especially when using higher-degree polynomials, to accurately estimate model parameters.\n",
    "\n",
    "**Situations for Using Polynomial Regression:**\n",
    "\n",
    "* **Curvilinear Patterns:** When the relationship between variables is visually curvilinear, polynomial regression can capture this curvature and provide a better fit.\n",
    "\n",
    "* **Nonlinear Transformations:** If applying a suitable nonlinear transformation to the data doesn't result in a linear relationship, polynomial regression can be a viable alternative.\n",
    "\n",
    "* **Domain Knowledge:** When you have domain knowledge suggesting a particular degree of polynomial is relevant, you can use that information to guide the choice of polynomial order.\n",
    "\n",
    "* **Limited Data Range:** If the data only spans a limited range where the relationship is nonlinear, polynomial regression might be preferred to capture that behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed69b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

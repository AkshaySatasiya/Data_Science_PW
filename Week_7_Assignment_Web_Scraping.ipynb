{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18118afa",
   "metadata": {},
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5b169",
   "metadata": {},
   "source": [
    "Web scraping refers to the __automated process of extracting data from websites.__ It involves fetching, parsing, and extracting information from the HTML code of web pages.\n",
    "\n",
    "Web scraping is used for various purposes, including:\n",
    "\n",
    "__Data Aggregation and Analysis__: Web scraping is commonly used to gather large amounts of data from different websites and consolidate it into a single database.\n",
    "\n",
    "__Content Monitoring__: Many businesses and individuals use web scraping to monitor changes and updates on specific websites.\n",
    "\n",
    "__Research and Data Collection__: Web scraping can be employed in various research fields to collect data for academic, scientific, or social studies.\n",
    "\n",
    "Web scraping is commonly used at:\n",
    "\n",
    "    1.E-commerce and Price Comparison\n",
    "    2.Financial and Investment Research\n",
    "    3.Real Estate and Property Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddedcd07",
   "metadata": {},
   "source": [
    "# Q2. What are the different methods used for Web Scraping?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133259b",
   "metadata": {},
   "source": [
    "There are several methods and techniques used for web scraping. Here are some common approaches:\n",
    "\n",
    "    1.Parsing HTML\n",
    "    2.Scrapy\n",
    "    3.BeautifulSoup\n",
    "    4.Requests\n",
    "    5.PyQuery\n",
    "    6.Postman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fc54f",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705d420",
   "metadata": {},
   "source": [
    "Beautiful Soup is a __Python library used for web scraping and parsing HTML or XML documents.__ It provides a convenient and intuitive way to extract data from web pages by navigating and manipulating the HTML or XML structure.\n",
    "\n",
    "Beautiful Soup is used for several reasons:\n",
    "\n",
    "    1.Parsing and Navigating HTML/XML\n",
    "    2.Handling Complex HTML Structure\n",
    "    3.Robust HTML/XML Parsing\n",
    "    4.Data Extraction\n",
    "    5.Integration with Other Libraries\n",
    "\n",
    "Beautiful Soup simplifies the process of web scraping and data extraction by providing a high-level API that abstracts away much of the underlying complexity. It is widely used and appreciated for its ease of use, versatility, and robustness in handling various types of HTML and XML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dda731",
   "metadata": {},
   "source": [
    "# Q4. Why is flask used in this Web Scraping project?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531be7a",
   "metadata": {},
   "source": [
    "Flask is a lightweight and flexible web framework written in Python. It is designed to make it easy to build web applications and APIs.\n",
    "\n",
    "it is used in web scraping projects for several reasons:\n",
    "\n",
    "    1.Web Interface\n",
    "    2.Routing and URL Handling\n",
    "    3.Templating Engine\n",
    "    4.Data Persistence\n",
    "    5.Task Scheduling and Background Jobs\n",
    "    6.Authentication and Security\n",
    "    7.Extensibility and Ecosystem\n",
    "\n",
    "Overall, Flask provides a flexible and lightweight framework for building web scraping projects with a web interface, data persistence, and various other features necessary for developing robust and scalable web scraping applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d952d1e",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea191a73",
   "metadata": {},
   "source": [
    "    1.CodePipeline\n",
    "    2.BeanStack\n",
    "    \n",
    "__1. AWS CodePipeline:__\n",
    "\n",
    "\n",
    "  AWS CodePipeline is a fully managed continuous delivery service that helps you automate your software release processes. It enables you to create, model, and orchestrate the stages involved in your software delivery workflow. \n",
    "\n",
    "   In a web scraping project, AWS CodePipeline can be utilized to automate the deployment of your scraping scripts or web application.\n",
    "   \n",
    "__2. AWS Beanstalk:__\n",
    "\n",
    "AWS Beanstalk is a fully managed platform-as-a-service (PaaS) offering that simplifies the deployment and management of web applications.\n",
    "\n",
    "In a web scraping project, AWS Elastic Beanstalk can be utilized to deploy and manage your web application that performs the scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b27010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
